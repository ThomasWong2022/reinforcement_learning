{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('quant': conda)",
   "display_name": "Python 3.7.9 64-bit ('quant': conda)",
   "metadata": {
    "interpreter": {
     "hash": "53410fa49836f37e2db933f2a1c7951cc241afccd53051166d8350041d9f0a2e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import ray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "ray.init()"
   ]
  },
  {
   "source": [
    "Load the current s&p 500 ticker list, we will only be trading on these stocks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tickers = open('s&p500_tickers.dat', 'r').read().split('\\n')\n",
    "print(tickers)"
   ]
  },
  {
   "source": [
    "Data start and end dates and initialise ticker dataframe dictionary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day = pd.Timedelta(days=1)\n",
    "\n",
    "i = 0\n",
    "cur_day = pd.to_datetime('1992-06-15', format=r'%Y-%m-%d') #pd.to_datetime('1992-06-15')\n",
    "end_day = pd.to_datetime('2020-01-01', format=r'%Y-%m-%d')\n",
    "\n",
    "end_df = pd.read_csv('equity_data/' + (end_day - one_day).strftime(r'%Y%m%d') + '.csv')\n",
    "ticker_df = end_df.loc[end_df.symbol.isin(tickers)] # Tickers that are in the dataframe on the last day\n",
    "ticker_dict = {ticker_df.symbol.iloc[i] : ticker_df.finnhub_id.iloc[i] for i in range(len(ticker_df.index))} # Create a mapping between tickers and finnhub_ids"
   ]
  },
  {
   "source": [
    "For all dates between start and end range, load the day into ticker dict with the key being ticker and dataframe indexed by day"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df_columns = pd.read_csv('equity_data/' + cur_day.strftime(r'%Y%m%d') + '.csv').columns\n",
    "ticker_dfs = { ticker : pd.DataFrame(index=pd.date_range(cur_day, end_day - one_day, freq='D'), columns=df_columns) for ticker in tickers }\n",
    "save_df = False\n",
    "if save_df:\n",
    "    pbar = tqdm(total=(end_day - cur_day).days)\n",
    "    while (cur_day != end_day):\n",
    "        pbar.update()\n",
    "        try:\n",
    "            day_df = pd.read_csv('equity_data/' + cur_day.strftime(r'%Y%m%d') + '.csv')\n",
    "        except FileNotFoundError:\n",
    "            cur_day += one_day\n",
    "            i += 1\n",
    "            continue\n",
    "        for ticker in ticker_dict.keys():\n",
    "            if ticker in day_df.symbol.values:\n",
    "                row = day_df.loc[day_df.finnhub_id == ticker_dict[ticker]]\n",
    "                if row.shape[0] == 2:\n",
    "                    print(ticker)\n",
    "                    print(row)\n",
    "                if not row.shape[0] == 0:\n",
    "                    ticker_dfs[ticker].loc[cur_day] = row.values[0, :]\n",
    "        cur_day += one_day\n",
    "        i += 1\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Loading logic, as the above is slow process and we dont want to perform it every time\n",
    "if save_df:\n",
    "    for ticker, ticker_frame in ticker_dfs.items():\n",
    "        ticker_frame.reset_index(inplace=True)\n",
    "        ticker_frame.to_feather('equity_data/stored/' + ticker.lower() + '.feather')\n",
    "else:\n",
    "    print('Loading from storage...')\n",
    "    for symbol in ticker_dict.keys():\n",
    "        ticker_dfs[symbol] = pd.read_feather('equity_data/stored/' + symbol.lower() + '.feather').set_index('index', drop=True)\n",
    "    print(ticker_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clear the data somewhat, we only want frames with more than 2000 days that have gaps no larger than 7 days\n",
    "to_delete = []\n",
    "for ticker, frame in ticker_dfs.items():\n",
    "    prev_day = frame.index[-1]\n",
    "    frame.dropna(axis='index', how='all', inplace=True)\n",
    "    if frame.empty:\n",
    "        to_delete.append(ticker)\n",
    "    elif len(frame.index) < 2000:\n",
    "        to_delete.append(ticker)\n",
    "    else:\n",
    "        for day in frame.index[::-1][1:]:\n",
    "            if (prev_day - day).days > 7: # if gap between datapoints larger than 7 days, remove\n",
    "                to_delete.append(ticker)\n",
    "                break\n",
    "            prev_day = day\n",
    "\n",
    "for ticker in to_delete:\n",
    "    del ticker_dfs[ticker]\n",
    "    print('Deleting ticker: ' + ticker)\n",
    "print(len(ticker_dfs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Align dataframes by date and create an intersection\n",
    "index_intersection = ticker_dfs[list(ticker_dfs.keys())[0]].index\n",
    "print(index_intersection)\n",
    "for ticker, ticker_frame in ticker_dfs.items():\n",
    "    index_intersection = index_intersection.intersection(ticker_frame.index)\n",
    "    print(ticker + ': ' + str(len(index_intersection)))\n",
    "print(index_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for ticker in ticker_dfs.keys():\n",
    "    ticker_dfs[ticker] = ticker_dfs[ticker].loc[index_intersection]\n",
    "print(ticker_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env config file structure for reference\n",
    "n_assets = 0\n",
    "n_features = 0\n",
    "config = {\n",
    "    'initial_balance': 0,\n",
    "    'initial_portfolio': [0]*n_assets,\n",
    "    'tickers': ['']*n_assets, # Tickers to trade, must correspond to tickers in dataframe dict! Implicitly defines number of assets\n",
    "    'indicators': [None]*n_features, # Indicator functions/classes to compute features for each stock, implicitly defines number of features. TODO: Support multidimensional indicators\n",
    "    'max_indicator_lookback': 0, # Number of days after which all indicators can compute proper values\n",
    "    'trading_days': 0,\n",
    "    'start_day_offset': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingEnv(gym.Env):\n",
    "\n",
    "    def __init__(self, env_config):\n",
    "        super(TradingEnv, self).__init__()\n",
    "\n",
    "        self._env_config = env_config\n",
    "        self._tickers = env_config['tickers']\n",
    "        self._indicator_funcs = self._env_config['indicators']\n",
    "        self._max_indicator_lookback = self._env_config['max_indicator_lookback'] # Number of days after which all indicators can compute proper values\n",
    "\n",
    "        self._n_assets = len(self._tickers)\n",
    "        self._n_features = len(self._indicator_funcs)\n",
    "\n",
    "        assert self._n_assets != 0, 'Number of assets must not be zero!'\n",
    "        assert self._n_features != 0, 'Number of features must not be zero!'\n",
    "\n",
    "        self._df_dict = env_config['df_dict'] # Daily OHCL data for each stock, indexed and aligned by day\n",
    "\n",
    "        self._days = self._df_dict[self._tickers[0]].index\n",
    "        self._trading_days = env_config['trading_days'] # Number of days the algorithm will be trading\n",
    "        self._start_day_idx = env_config['start_day_offset'] # Offset of the first trading day from the first dataframe day\n",
    "        \n",
    "        if self._start_day_idx is not None:\n",
    "            assert self._start_day_idx >= self._max_indicator_lookback, 'start_day_offset must be larger than max_indicator_lookback in order to properly initialise all indicators'\n",
    "            assert self._start_day_idx + self._trading_days <= len(self._days), 'start_day_idx + trading_days must be lower than the number of days'\n",
    "        else:\n",
    "            self._start_day_idx\n",
    "        \n",
    "        assert self._trading_days + self._max_indicator_lookback <= len(self._days) ,'The sum of trading_days + max_indicator_lookback must be lower than the number of days in the dataframe'\n",
    "\n",
    "        self._initial_balance = self._env_config['initial_balance']\n",
    "        self._initial_portfolio = self._env_config['initial_portfolio'] if self._env_config['initial_portfolio'] is not None else [0] * self._n_assets\n",
    "\n",
    "        assert len(self._initial_portfolio) == self._n_assets, 'Size of initial portfolio must equal the number of assets!'\n",
    "\n",
    "        action_shape = (self._n_assets + 1,)\n",
    "        obs_shape = (self._n_features*self._n_assets + 1,)\n",
    "\n",
    "        self.action_space = gym.spaces.Box(np.full(action_shape, 0), np.full(action_shape, 1), shape=action_shape, dtype=np.float16) # Action space is the assets + cash for rebalancing\n",
    "        self.observation_space = gym.spaces.Box(np.full(obs_shape, 0), np.inf, shape=obs_shape, dtype=np.float16) # Observation space is all the features for each asset + cash\n",
    "        self.max_episode_steps = self._trading_days\n",
    "\n",
    "    def reset(self):\n",
    "        self._balance = self._initial_balance\n",
    "        self._portfolio = self._initial_portfolio\n",
    "\n",
    "        if self._start_day_idx is None:\n",
    "            self._start_day_idx = np.random.randint(self._max_indicator_lookback, len(self._days) - self._trading_days) # If no start day chosen, generate a random start\n",
    "        self._cur_day_idx = self._start_day_idx\n",
    "        self._cur_day = self._days[self._cur_day_idx]\n",
    "        self._cur_day_idx += 1 # Advance one day\n",
    "        \n",
    "        indicators = self._compute_indicators(self._cur_day) # Compute the indicators for the start date\n",
    "        \n",
    "        return np.append(indicators, self._balance) # Observation is number of indicators * number of assets + 1\n",
    "\n",
    "    def _compute_indicators(self, day):\n",
    "        features = np.empty((self._n_features*self._n_assets,))\n",
    "        for (i, ticker) in enumerate(self._tickers):\n",
    "            for (j, indicator) in enumerate(self._indicator_funcs):\n",
    "                ticker_frame_slice = self._df_dict[ticker].loc[self._days[self._start_day_idx] - pd.Timedelta(days=1)*self._max_indicator_lookback:(day + pd.Timedelta(days=1))] # Get the relevant dataframe up until this day (inclusive)\n",
    "                features[i*self._n_features + j] = indicator(ticker_frame_slice)\n",
    "        return features\n",
    "\n",
    "    def _asset_prices(self, day): # Use open prices on the current day\n",
    "        prices = np.empty((self._n_assets,))\n",
    "        for i, ticker in enumerate(self._tickers):\n",
    "            prices[i] = self._df_dict[ticker].loc[day].open\n",
    "        return prices\n",
    "\n",
    "    def _portfolio_val(self, portfolio, balance, day):\n",
    "        return np.dot(self._asset_prices(self._cur_day), portfolio) + balance\n",
    "    \n",
    "    def _rebalance(self, actions): # TODO: Test this more to see if it makes sense\n",
    "        weightings = self._softmax(actions) # First weight is for cash\n",
    "\n",
    "        prices = self._asset_prices(self._cur_day) # Get the open prices of assets on the current day\n",
    "        portfolio_val = np.dot(prices, self._portfolio) + self._balance\n",
    "        return (portfolio_val*np.divide(weightings[1:], prices), portfolio_val*weightings[0]) # Rebalanced portfolio in the form of (assets, cash)\n",
    "\n",
    "    def _reward(self):\n",
    "        # For now just compute the increase in portfolio value\n",
    "        return 1 - self._portfolio_val(self._portfolio, self._balance, self._cur_day) / self._portfolio_val(self._initial_portfolio, self._initial_balance, self._days[self._start_day_idx])\n",
    "\n",
    "    def step(self, action):\n",
    "        self._cur_day = self._days[self._cur_day_idx]\n",
    "        #print('Day: ' + str(self._cur_day))\n",
    "        (self._portfolio, self._balance) = self._rebalance(action)\n",
    "\n",
    "        obs = np.append(self._compute_indicators(self._cur_day), self._balance)\n",
    "        rw = self._reward()\n",
    "        done = (self._cur_day_idx - self._start_day_idx) >= self._trading_days\n",
    "        info = {} # TODO: Add info here\n",
    "\n",
    "        self._cur_day_idx += 1 # Advance one day\n",
    "        return obs, rw, done, info\n",
    "    \n",
    "    def _softmax(self, x):\n",
    "        \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_indicator = lambda df: df.close[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_assets = len(ticker_dfs.keys())\n",
    "env_config = {\n",
    "    'initial_balance': 1E6,\n",
    "    'initial_portfolio': [0]*n_assets,\n",
    "    'tickers': list(ticker_dfs.keys()), # Tickers to trade, must correspond to tickers in dataframe dict! Implicitly defines number of assets\n",
    "    'indicators': [close_indicator], # Indicator functions/classes to compute features for each stock, implicitly defines number of features. TODO: Support multidimensional indicators\n",
    "    'max_indicator_lookback': 0, # Number of days after which all indicators can compute proper values\n",
    "    'trading_days': 100,\n",
    "    'start_day_offset': None,\n",
    "    'df_dict': ticker_dfs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import ray.rllib.agents.ppo as ppo\n",
    "import ray.rllib.models.catalog as catalog\n",
    "import ray.tune as tune\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "config[\"num_gpus\"] = 0\n",
    "config[\"num_workers\"] = 5\n",
    "config[\"rollout_fragment_length\"] = 100\n",
    "config[\"train_batch_size\"] = 500\n",
    "#config[\"framework\"] = \"torch\"\n",
    "config[\"env_config\"] = env_config\n",
    "config[\"log_level\"] = \"DEBUG\"\n",
    "config[\"env\"] = TradingEnv\n",
    "\n",
    "model_config = catalog.MODEL_DEFAULTS.copy()\n",
    "model_config[\"use_lstm\"] = True\n",
    "model_config[\"max_seq_len\"] = 100\n",
    "\n",
    "#trainer = ppo.PPOTrainer(config=config, env=TradingEnv)\n",
    "tune.run(ppo.PPOTrainer, stop={\"training_iteration\": 100}, config=config, local_dir='ray_results')\n",
    "\n",
    "\"\"\"\n",
    "# Can optionally call trainer.restore(path) to load a checkpoint.\n",
    "\n",
    "for i in range(1000):\n",
    "    # Perform one iteration of training the policy with PPO\n",
    "    result = trainer.train()\n",
    "    print(pretty_print(result))\n",
    "    \n",
    "    checkpoint = trainer.save()\n",
    "    print(\"checkpoint saved at\", checkpoint)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}